# **Towards Practical Industrial Anomaly Detection** [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)


## To do list
1. æ±‡æ€»ç»¼è¿°é‡Œè¾¹æ‰€æœ‰ç›¸å…³è®ºæ–‡çš„æ ‡é¢˜ã€å‡ºç‰ˆç‰©ï¼›æŒ‰ç…§ç»¼è¿°ä¸­çš„ç±»åˆ«å¡«å…¥[Summary-before-2025].æ›´å°çš„ç›®å½•ç”¨tagæ¥è¡¨ç¤ºï¼Œä¾‹å¦‚åŸºäºé‡å»ºçš„æ–¹æ³•å¯ä»¥ç”¨[![Info](https://img.shields.io/badge/Method-Reconstruction-blue)](#). åŸºäºå¼‚å¸¸åˆæˆçš„å¯ä»¥ç”¨[![Info](https://img.shields.io/badge/Method-Generation-yellow)](#). æ¯ä¸ªé¢œè‰²æœ‰åŒºåˆ«ä¸€äº›
2. [Summary-before-2025]ä¸­çš„æ¨¡æ¿ä¸º: Paper_name [[å‡ºç‰ˆç‰©]()] [[Code]()]  [![Info](https://img.shields.io/badge/Model-ViT_+_MemoryBank_+_Real3D--AD-blue)](#)
3. å…¶ä»–éƒ¨åˆ†çš„æ¨¡æ¿ä¸ºPaper_name [[paper]()] [[Code]()]  [![Info](https://img.shields.io/badge/Model-ViT_+_MemoryBank_+_Real3D--AD-blue)](#)
4. è°ƒç ”ä»Šå¹´å¼‚å¸¸æ£€æµ‹é¡¶ä¼šçš„ç§ç±»å’Œé¡ºåºï¼Œä¿®æ”¹ Quick Navigationï¼Œå¹¶æ›´æ–°åˆ°ä¸‹è¾¹çš„æ ‡é¢˜å†…ï¼Œæ‰“ä¸Štagï¼Œè¿™ä¸ªtagå¯ä»¥é•¿ä¸€äº›ï¼Œä¾‹å¦‚[![Info](https://img.shields.io/badge/Model-ViT_+2D+_CLIP-blue)](#)
5. wosä¸Šæ£€ç´¢æœŸåˆŠæ–‡ç« ï¼Œä»…2025å¹´å³å¯ï¼Œé‡ç‚¹åœ¨PAMIã€IJCVã€IEEE/ACM Transï¼Œä»¥åŠéƒ¨åˆ†è¿˜ä¸é”™çš„çˆ±æ€å”¯å°”æœŸåˆŠPRã€KBSã€AEIã€JMSã€CIIç­‰ï¼ˆè¦ç­›é€‰ï¼Œè´¨é‡å·®çš„ä¸éœ€è¦åˆ—å‡ºæ¥ï¼‰
6. ç»¼è¿°æ–‡ç« éœ€è¦å†æ£€ç´¢ä¸€ä¸‹ï¼Œå®æ—¶ä¿æŒæ›´æ–°
7. BenchMarkç›´æ¥å°†ç»¼è¿°é‡Œè¾¹çš„æ•°æ®é›†è¡¨æ ¼å¡«å……å³å¯
8. Recent Featured Paperså¯ä»¥æ”¾ä¸€äº›ç›®å‰æ¯”è¾ƒçƒ­é—¨çš„ï¼ˆå°¤å…¶æ˜¯æˆ‘ä»¬è‡ªå·±æœ€è¿‘æ–°å‘è¡¨çš„æ–‡ç« ï¼‰
9. Our-Publications é‡Œè¾¹æ”¾ä¸€äº›æˆ‘ä»¬å‘çš„æ¯”è¾ƒå¥½é¡¶ä¼šå’Œtransæ–‡ç« åšå®£ä¼ 



---
## ğŸ… Recent Featured Papers
- A Survey on Vision-Language-Action Models: An Action Tokenization Perspective [[paper](https://arxiv.org/pdf/2507.01925)]
- A Survey on Vision-Language-Action Models for Autonomous Driving [[paper](https://arxiv.org/pdf/2506.24044)] [[project](https://github.com/JohnsonJiang1996/Awesome-VLA4AD)]  
- Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends [[paper](https://arxiv.org/pdf/2506.20966)] [[project](https://github.com/AoqunJin/Awesome-VLA-Post-Training)]  
- Foundation Models in Robotics: Applications, Challenges, and the Future [[paper](https://arxiv.org/pdf/2312.07843)] [[project](https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models)]

---
## ğŸ”— Quick Navigation
- [Our-Publications](#Our-Publications) | [Survey](#Survey) | [BenchMark](#BenchMark) | [AAAI-2026](#AAAI-2026) | [NIPS-2025](#NIPS-2025) | [ICCV-2025](#ICCV-2025) | [CVPR-2025](#CVPR-2025) | [IJCAI-2025](#IJCAI-2025) | [Journal-2025](#Journal-2025) | [Summary-before-2025](#Summary-before-2025)

---




## Survey

<details open>
<summary>ğŸ“š Show/Hide Survey Papers</summary>

- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]

</details>

---


## BenchMark

|  Name  |   Venue  |   Date   |   Source   |   Modality   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| MVTec | XXXX | 2022 | paper name+link | image |
| MVTec | XXXX | 2022 | paper name+link | image |
| MVTec | XXXX | 2022 | paper name+link | image |
| MVTec | XXXX | 2022 | paper name+link | image |





---




## **Our-Publications**
<details open>
<summary>ğŸ“š Show/Hide 2024 Papers</summary>

Template: Paper_name [[Paper]()] [[Code]()]  [![Info](https://img.shields.io/badge/Model-ViT_+_MemoryBank_+_Real3D--AD-blue)](#)
 - A Survey on Vision-Language-Action Models: An Action Tokenization Perspective. [[Paper]()] [[Code]()] [![Info](https://img.shields.io/badge/Model-ViT_+_MemoryBank_+_Real3D--AD-blue)](#)




</details>

---





## AAAI-2026

<details open>
<summary>ğŸ“š Show/Hide AAAI-2026 Papers</summary>


- [2025] Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey [[paper](https://arxiv.org/pdf/2508.13073)] [[project](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)]  [![AAAA](https://img.shields.io/badge/AAAA-BBBBB-blue)](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)
- [2025] Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning [[paper](https://arxiv.org/pdf/2508.10399)] [![Info](https://img.shields.io/badge/Model-ViT_+_MemoryBank_+_Real3D--AD-blue?style=flat-square)](#)
- [2025] Foundation Model Driven Robotics: A Comprehensive Review [[paper](https://arxiv.org/pdf/2507.10087)]
- [2025] [**PKU-PsiBot**] A Survey on Vision-Language-Action Models: An Action Tokenization Perspective [[paper](https://arxiv.org/pdf/2507.01925)]
- [2025] A Survey on Vision-Language-Action Models for Autonomous Driving [[paper](https://arxiv.org/pdf/2506.24044)] [[project](https://github.com/JohnsonJiang1996/Awesome-VLA4AD)]  
- [2025] Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends [[paper](https://arxiv.org/pdf/2506.20966)] [[project](https://github.com/AoqunJin/Awesome-VLA-Post-Training)]  
- [2025] [**IJRR 25**] Foundation Models in Robotics: Applications, Challenges, and the Future [[paper](https://arxiv.org/pdf/2312.07843)] [[project](https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models)]
- [2025] Deep Reinforcement Learning for Robotics: A Survey of Real-World Successes [[paper](https://www.arxiv.org/abs/2408.03539)]
- [2025] A Survey on Diffusion Policy for Robotic Manipulation: Taxonomy, Analysis, and Future Directions [[paper](https://doi.org/10.36227/techrxiv.174378343.39356214/v1)] [[project](https://github.com/HITSZ-Robotics/DiffusionPolicy-Robotics)]  
- [2025] Embodied Intelligent Industrial Robotics: Concepts and Techniques [[paper](https://arxiv.org/pdf/2505.09305)] [[project](https://github.com/jackeyzengl/Embodied_Intelligent_Industrial_Robotics_Paper_List)] 
- [2025] Neural Brain: A Neuroscience-inspired Framework for Embodied Agents [[paper](https://arxiv.org/pdf/2505.07634)] [[project](https://github.com/CNJianLiu/Neural-Brain-for-Embodied-Agents)] 
- [2025] Vision-Language-Action Models: Concepts, Progress, Applications and Challenges [[paper](https://arxiv.org/pdf/2505.04769v1)]
- [2025] A Survey of Robotic Navigation and Manipulation with Physics Simulators in the Era of Embodied AI [[paper](https://arxiv.org/pdf/2505.01458)]
- [2025] Multimodal Perception for Goal-oriented Navigation: A Survey [[paper](https://arxiv.org/pdf/2504.15643)]
- [2025] Diffusion Models for Robotic Manipulation: A Survey [[paper](https://arxiv.org/pdf/2504.08438)]
- [2025] Dexterous Manipulation through Imitation Learning: A Survey [[paper](https://arxiv.org/pdf/2504.03515)]
- [2025] Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision [[paper](https://arxiv.org/pdf/2504.02477)] [[project](https://github.com/Xiaofeng-Han-Res/MF-RV)] 
- [2025] SE(3)-Equivariant Robot Learning and Control: A Tutorial Survey [[paper](https://arxiv.org/pdf/2503.09829)]
- [2025] Generative Artificial Intelligence in Robotic Manipulation: A Survey [[paper](https://arxiv.org/pdf/2503.03464)] [[project](https://github.com/GAI4Manipulation/AwesomeGAIManipulation)] 
- [2025] Development Report of Embodied Intelligence (Chinese) [[paper](https://www.caict.ac.cn/kxyj/qwfb/bps/202408/P020240830312499650772.pdf)]
- [2025] Survey on Vision-Language-Action Models [[paper](https://arxiv.org/pdf/2502.06851)]
- [2025] Exploring Embodied Multimodal Large Models: Development, Datasets, and Future Directions [[paper](https://arxiv.org/pdf/2502.15336)]
- [2024] Embodied-AI with large models: research and challenges [[paper](https://www.sciengine.com/SSI/doi/10.1360/SSI-2024-0076)]
- [2024] A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- [2024] A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- [2024] Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- [2024] Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]


</details>

---

## NIPS-2025

<details open>
<summary>ğŸ“š Show/Hide NIPS-2025 Papers</summary>

- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]

</details>

---



## ICCV-2025

<details open>
<summary>ğŸ“š Show/Hide ICCV-2025 Papers</summary>

- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]

</details>

---



## CVPR-2025

<details open>
<summary>ğŸ“š Show/Hide CVPR-2025 Papers</summary>

- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]

</details>

---


## IJCAI-2025

<details open>
<summary>ğŸ“š Show/Hide IJCAI-2025 Papers</summary>

- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]

</details>

---



## Journal-2025

<details open>
<summary>ğŸ“š Show/Hide Journal-2025 Papers</summary>

- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]

</details>

---










## Summary-before-2025

<details open>
<summary>ğŸ“š Show/Hide Summary-before-2025 Papers</summary>

- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]

</details>


### 2D ANOMALY DETECTION
#### ğŸ“ŠUnsupervised 
- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]



#### ğŸ“ŠSemi-supervised
- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]


#### ğŸ“ŠZero/Few-shot 
- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]


---
### 3D ANOMALY DETECTION

#### ğŸ“ŠPoint Cloud
- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]


#### ğŸ“ŠRGBD
- A Survey on Vision-Language-Action Models for Embodied AI [[paper](https://arxiv.org/abs/2405.14093)]
- A Survey of Embodied Learning for Object-Centric Robotic Manipulation [[paper](https://arxiv.org/pdf/2408.11537)]
- Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI [[paper](https://arxiv.org/pdf/2407.06886)]
- Vision-language navigation: a survey and taxonomy [[paper](https://arxiv.org/pdf/2108.11544)]

---






## BibTex Citation

If you find this paper and repository useful, please cite our paperâ˜ºï¸.

```
@article{ADSurvey,
  title={A comprehensive survey for real-world industrial defect detection: Challenges, approaches, and prospects},
  author={Cheng, Yuqi and Cao, Yunkang and Yao, Haiming and Luo, Wei and Jiang, Cheng and Zhang, Hui and Shen, Weiming},
  journal={arXiv preprint arXiv:2507.13378},
  year={2025}
}
```
## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=hustCYQ/Towards-Practical-Industrial-Anomaly-Detection&type=Date)](https://www.star-history.com/#hustCYQ/Towards-Practical-Industrial-Anomaly-Detection&Date)
























